{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14xjc8oWzDJBkwzB5tULxmEjoFlySxbqb",
      "authorship_tag": "ABX9TyOzHT/RFGDQdTKkm/BLbuTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkitGole007/CS541-DeepLearning/blob/hw4/pytorch_pre-requisite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMG8HhdAimr4",
        "outputId": "f2b1d097-5f01-43ed-8e1a-8e07d7a9ef68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]], dtype=torch.int16)\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n",
            "A random tensor:\n",
            "tensor([[0.3126, 0.3791],\n",
            "        [0.3087, 0.0736]])\n",
            "\n",
            "A different random tensor:\n",
            "tensor([[0.4216, 0.0691],\n",
            "        [0.2332, 0.4047]])\n",
            "\n",
            "And another random tensor:\n",
            "tensor([[0.3126, 0.3791],\n",
            "        [0.3087, 0.0736]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "z = torch.zeros((2,3),dtype=torch.int16)\n",
        "print(z)\n",
        "\n",
        "i = torch.ones((5, 3), dtype=torch.int16)\n",
        "print(i)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "r1 = torch.rand(2, 2)\n",
        "print('A random tensor:')\n",
        "print(r1)\n",
        "\n",
        "r2 = torch.rand(2, 2)\n",
        "print('\\nA different random tensor:')\n",
        "print(r2) # new values\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "r3 = torch.rand(2, 2)\n",
        "print('\\nAnd another random tensor:')\n",
        "print(r3) # new values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1+r2\n",
        "r = (torch.rand(2,2)-0.5)\n",
        "print(r)\n",
        "\n",
        "print(torch.abs(r))\n",
        "\n",
        "print(torch.std_mean(r))\n",
        "print(torch.max(r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-huHzQpi4pd",
        "outputId": "43de32c9-1ea1-4f3b-c2f0-dbc691d8c10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0784, -0.4309],\n",
            "        [-0.2668, -0.0953]])\n",
            "tensor([[0.0784, 0.4309],\n",
            "        [0.2668, 0.0953]])\n",
            "(tensor(0.1656), tensor(-0.2179))\n",
            "tensor(-0.0784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "X = torch.randn(100, 1)    # 100 samples, 1 feature\n",
        "y = 3 * X + 2 + 0.1 * torch.randn(100, 1)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.linear = nn.Linear(1,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = LinearRegression()\n",
        "loss = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "  y_pred = model(X)\n",
        "  l = loss(y_pred,y)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwaMHTnZj7cu",
        "outputId": "758c54ca-6073-4b92-be82-dbf49aa38f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.2628\n",
            "Epoch [200/1000], Loss: 0.0172\n",
            "Epoch [300/1000], Loss: 0.0091\n",
            "Epoch [400/1000], Loss: 0.0088\n",
            "Epoch [500/1000], Loss: 0.0088\n",
            "Epoch [600/1000], Loss: 0.0088\n",
            "Epoch [700/1000], Loss: 0.0088\n",
            "Epoch [800/1000], Loss: 0.0088\n",
            "Epoch [900/1000], Loss: 0.0088\n",
            "Epoch [1000/1000], Loss: 0.0088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.randn(100,2)\n",
        "y = torch.randint(0,3,(100,))\n",
        "\n",
        "class SoftmaxRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "     super(SoftmaxRegression, self).__init__()\n",
        "     self.linear = nn.Linear(2,3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "  def predict(self, x):\n",
        "    y_pred = self.forward(x)\n",
        "    return torch.argmax(y_pred, dim=1)\n",
        "\n",
        "num_epochs = 1000\n",
        "model = SoftmaxRegression()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  y_pred = model(X)\n",
        "  l = loss(y_pred,y)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}')\n",
        "        print(model.predict(X)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbdJVa-cffzI",
        "outputId": "a384f9f5-0d2e-47a0-8325-b4631b82f3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 1.2787\n",
            "tensor(2)\n",
            "Epoch [200/1000], Loss: 1.1914\n",
            "tensor(2)\n",
            "Epoch [300/1000], Loss: 1.1362\n",
            "tensor(2)\n",
            "Epoch [400/1000], Loss: 1.1041\n",
            "tensor(2)\n",
            "Epoch [500/1000], Loss: 1.0871\n",
            "tensor(2)\n",
            "Epoch [600/1000], Loss: 1.0786\n",
            "tensor(2)\n",
            "Epoch [700/1000], Loss: 1.0745\n",
            "tensor(2)\n",
            "Epoch [800/1000], Loss: 1.0725\n",
            "tensor(2)\n",
            "Epoch [900/1000], Loss: 1.0716\n",
            "tensor(2)\n",
            "Epoch [1000/1000], Loss: 1.0711\n",
            "tensor(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "train_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/datasets/fashion_mnist_train_images.npy\")\n",
        "train_labels = np.load(\"/content/drive/MyDrive/Colab Notebooks/datasets/fashion_mnist_train_labels.npy\")\n",
        "test_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/datasets/fashion_mnist_test_images.npy\")\n",
        "test_labels = np.load(\"/content/drive/MyDrive/Colab Notebooks/datasets/fashion_mnist_test_labels.npy\")\n",
        "\n",
        "train_images_tensor = torch.from_numpy(train_images)\n",
        "train_labels_tensor = torch.from_numpy(train_labels).long()\n",
        "test_images_tensor = torch.from_numpy(test_images)\n",
        "test_labels_tensor = torch.from_numpy(test_labels).long()\n",
        "\n",
        "train_size = int(0.8 * len(train_images_tensor))\n",
        "val_size = len(train_images_tensor) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(TensorDataset(train_images_tensor, train_labels_tensor),[train_size,val_size])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(test_images_tensor, test_labels_tensor), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class SoftmaxRegression(nn.Module):\n",
        "  def __init__(self, input_size = 784, hidden_size = 128, output_size = 10):\n",
        "     super(SoftmaxRegression, self).__init__()\n",
        "     self.fn1 = nn.Linear(input_size,hidden_size)\n",
        "     self.fn2 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 784)\n",
        "    x = torch.relu(self.fn1(x))\n",
        "    x = self.fn2(x)\n",
        "    return x\n",
        "\n",
        "epsilon = 0.001\n",
        "alpha = 0.01\n",
        "epochs = 100\n",
        "\n",
        "model = SoftmaxRegression()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer  = optim.SGD(model.parameters(),lr=epsilon,weight_decay=alpha)\n",
        "\n",
        "def train(model, train_loader, val_loader, loss, optimizer, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for image,label in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(image)\n",
        "      l = loss(y_pred,label)\n",
        "      l.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += l.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    total = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for image,label in val_loader:\n",
        "        outputs = model(image)\n",
        "        l = loss(outputs, label)\n",
        "        val_loss += l\n",
        "        predicted = torch.argmax(outputs, 1)\n",
        "        total = label.size(0)\n",
        "        count = (predicted == label).sum().item()\n",
        "\n",
        "    if (epoch+1)%10 == 0:\n",
        "      print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
        "            f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {100 * count / total:.2f}%\")\n",
        "\n",
        "train(model, train_loader, val_loader, loss, optimizer, epochs)\n",
        "\n",
        "def evaluate(model, test_loader, loss):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  total = 0\n",
        "  count = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for image,label in val_loader:\n",
        "      outputs = model(image)\n",
        "      l = loss(outputs, label)\n",
        "      test_loss += l\n",
        "      predicted = torch.argmax(outputs, 1)\n",
        "      total = label.size(0)\n",
        "      count = (predicted == label).sum().item()\n",
        "  print(f\"Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {100 * count / total:.2f}%\")\n",
        "\n",
        "evaluate(model, test_loader, loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk1rUhDmziJt",
        "outputId": "5040d8d1-d6a3-4bcf-ffca-1c84329b77dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Train Loss: 0.3758, Val Loss: 0.4549, Val Accuracy: 78.12%\n",
            "Epoch [20/100], Train Loss: 0.3180, Val Loss: 0.3954, Val Accuracy: 90.62%\n",
            "Epoch [30/100], Train Loss: 0.2863, Val Loss: 0.3879, Val Accuracy: 81.25%\n",
            "Epoch [40/100], Train Loss: 0.2621, Val Loss: 0.3723, Val Accuracy: 87.50%\n",
            "Epoch [50/100], Train Loss: 0.2464, Val Loss: 0.3896, Val Accuracy: 96.88%\n",
            "Epoch [60/100], Train Loss: 0.2315, Val Loss: 0.3788, Val Accuracy: 96.88%\n",
            "Epoch [70/100], Train Loss: 0.2170, Val Loss: 0.4145, Val Accuracy: 87.50%\n",
            "Epoch [80/100], Train Loss: 0.2070, Val Loss: 0.3902, Val Accuracy: 93.75%\n",
            "Epoch [90/100], Train Loss: 0.1977, Val Loss: 0.4592, Val Accuracy: 87.50%\n",
            "Epoch [100/100], Train Loss: 0.1856, Val Loss: 0.4191, Val Accuracy: 96.88%\n",
            "Test Loss: 0.5019, Test Accuracy: 96.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHanOjrL0niL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}